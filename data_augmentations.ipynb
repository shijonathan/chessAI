{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b851b0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] (11785614, 768)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = gzip.GzipFile('data_processed.npy.gz', \"r\")\n",
    "data = np.load(f, allow_pickle=True)\n",
    "f.close()\n",
    "print(data, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "906d7b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0] (11785614,)\n"
     ]
    }
   ],
   "source": [
    "f = gzip.GzipFile('results_processed.npy.gz', \"r\")\n",
    "labels = np.load(f, allow_pickle=True)\n",
    "f.close()\n",
    "print(labels, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d36262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing -1 to 2 cause crossentropy hates it or something\n",
    "data = data[0:500000]\n",
    "labels = labels[0:500000]\n",
    "temp = []\n",
    "for lab in labels:\n",
    "    if lab == -1:\n",
    "        temp.append(2)\n",
    "    else:\n",
    "        temp.append(lab)\n",
    "        \n",
    "labels = np.array(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4ef72b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xtr (450000, 768)\n",
      "ytr (450000,)\n",
      "Xts (50000, 768)\n",
      "yts (50000,)\n"
     ]
    }
   ],
   "source": [
    "#10% as the test data\n",
    "Xtr, Xts, ytr, yts = train_test_split(data, labels, test_size=0.10)\n",
    "print(\"Xtr\", Xtr.shape)\n",
    "print(\"ytr\", ytr.shape)\n",
    "print(\"Xts\", Xts.shape)\n",
    "print(\"yts\", yts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd672bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the right dtypes for the tensors\n",
    "x_tr = torch.from_numpy(Xtr)\n",
    "x_tr = x_tr.type(torch.FloatTensor)\n",
    "y_tr = torch.from_numpy(ytr)\n",
    "y_tr = y_tr.type(torch.LongTensor)\n",
    "x_ts = torch.from_numpy(Xts)\n",
    "x_ts = x_ts.type(torch.FloatTensor)\n",
    "y_ts = torch.from_numpy(yts)\n",
    "y_ts = y_ts.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e21e3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning into the loader class\n",
    "traindata = torch.utils.data.TensorDataset(x_tr, y_tr)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    traindata,\n",
    "    batch_size = 100000\n",
    ")\n",
    "\n",
    "testdata = torch.utils.data.TensorDataset(x_ts, y_ts)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testdata,\n",
    "    batch_size = 10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c280a32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple neural network\n",
    "n_in = 768\n",
    "n_out = 3\n",
    "learning_rate = 0.001\n",
    "K = 770\n",
    "P = 1.0\n",
    "epochs = 80\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_in, K) \n",
    "        torch.nn.init.kaiming_uniform_(self.fc1.weight) #He initialization\n",
    "        self.fc2 = nn.Linear(K, n_out)\n",
    "        torch.nn.init.kaiming_uniform_(self.fc2.weight) #He initialization\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "#criterion = torch.nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c035f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline\n",
    "traccs = []\n",
    "tsaccs = []\n",
    "for epoch in range(epochs):\n",
    "    correct = 0\n",
    "    size = 0\n",
    "    net.train()\n",
    "    for b, (x, y) in enumerate(trainloader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "        output = net(x)\n",
    "        #print(output)\n",
    "        #acu += (output.argmax(1) == y).float().sum().item()\n",
    "        cor = (output.argmax(1) == y).float().sum().item()\n",
    "\n",
    "        correct += cor\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        size += len(x)\n",
    "\n",
    "    #accs.append(100 * (acu / len(y_tr)))\n",
    "    traccs.append((100 * correct) / size)\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    size = 0\n",
    "    with torch.no_grad():\n",
    "        for b, (x, y) in enumerate(testloader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad() \n",
    "            output = net(x)\n",
    "            #print(output)\n",
    "            #acu += (output.argmax(1) == y).float().sum().item()\n",
    "            cor = (output.argmax(1) == y).float().sum().item()\n",
    "\n",
    "            correct += cor\n",
    "            size += len(x)\n",
    "\n",
    "        #accs.append(100 * (acu / len(y_tr)))\n",
    "        tsaccs.append((100 * correct) / size)\n",
    "\n",
    "print(\"max training accuracy: \", max(traccs))\n",
    "print(\"max testing accuracy: \", max(tsaccs))\n",
    "lab = \"training accuracy\"\n",
    "plt.figure(1)\n",
    "plt.plot(traccs, label=lab)\n",
    "plt.title(\"Change in Training Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "lab = \"testing accuracy\"\n",
    "plt.figure(2)\n",
    "plt.plot(tsaccs, label=lab)\n",
    "plt.title(\"Change in Testing Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed25eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep neural network\n",
    "n_in = 768\n",
    "n_out = 3\n",
    "learning_rate = 0.001\n",
    "P = 1.0\n",
    "epochs = 80\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_in, 770) \n",
    "        torch.nn.init.kaiming_uniform_(self.fc1.weight) #He initialization\n",
    "        self.fc2 = nn.Linear(770, 700)\n",
    "        torch.nn.init.kaiming_uniform_(self.fc2.weight) #He initialization\n",
    "        self.fc3 = nn.Linear(700, 600) \n",
    "        torch.nn.init.kaiming_uniform_(self.fc3.weight) #He initialization\n",
    "        self.fc4 = nn.Linear(600, 500)\n",
    "        torch.nn.init.kaiming_uniform_(self.fc4.weight) #He initialization\n",
    "        self.fc5 = nn.Linear(500, 400) \n",
    "        torch.nn.init.kaiming_uniform_(self.fc5.weight) #He initialization\n",
    "        self.fc6 = nn.Linear(400, 300)\n",
    "        torch.nn.init.kaiming_uniform_(self.fc6.weight) #He initialization\n",
    "        self.fc7 = nn.Linear(300, 200) \n",
    "        torch.nn.init.kaiming_uniform_(self.fc7.weight) #He initialization\n",
    "        self.fc8 = nn.Linear(200, 100)\n",
    "        torch.nn.init.kaiming_uniform_(self.fc8.weight) #He initialization\n",
    "        self.fc9 = nn.Linear(100, 50) \n",
    "        torch.nn.init.kaiming_uniform_(self.fc9.weight) #He initialization\n",
    "        self.fc10 = nn.Linear(50, n_out)\n",
    "        torch.nn.init.kaiming_uniform_(self.fc10.weight) #He initialization\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = F.relu(self.fc8(x))\n",
    "        x = F.relu(self.fc9(x))\n",
    "        x = F.sigmoid(self.fc10(x))\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "#criterion = torch.nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f32f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "traccs = []\n",
    "tsaccs = []\n",
    "for epoch in range(epochs):\n",
    "    correct = 0\n",
    "    size = 0\n",
    "    net.train()\n",
    "    for b, (x, y) in enumerate(trainloader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "        output = net(x)\n",
    "        #print(output)\n",
    "        #acu += (output.argmax(1) == y).float().sum().item()\n",
    "        cor = (output.argmax(1) == y).float().sum().item()\n",
    "\n",
    "        correct += cor\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        size += len(x)\n",
    "\n",
    "    #accs.append(100 * (acu / len(y_tr)))\n",
    "    traccs.append((100 * correct) / size)\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    size = 0\n",
    "    with torch.no_grad():\n",
    "        for b, (x, y) in enumerate(testloader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad() \n",
    "            output = net(x)\n",
    "            #print(output)\n",
    "            #acu += (output.argmax(1) == y).float().sum().item()\n",
    "            cor = (output.argmax(1) == y).float().sum().item()\n",
    "\n",
    "            correct += cor\n",
    "            size += len(x)\n",
    "\n",
    "        #accs.append(100 * (acu / len(y_tr)))\n",
    "        tsaccs.append((100 * correct) / size)\n",
    "\n",
    "print(\"max training accuracy: \", max(traccs))\n",
    "print(\"max testing accuracy: \", max(tsaccs))\n",
    "lab = \"training accuracy\"\n",
    "plt.figure(1)\n",
    "plt.plot(traccs, label=lab)\n",
    "plt.title(\"Change in Training Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "lab = \"tessting accuracy\"\n",
    "plt.figure(2)\n",
    "plt.plot(tsaccs, label=lab)\n",
    "plt.title(\"Change in Testing Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db2a928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worldview(dataset):\n",
    "    \"\"\"\n",
    "    args:\n",
    "    dataset: Dataset\n",
    "   \n",
    "    returns: \n",
    "    context_dataset: List\n",
    "    \"\"\"\n",
    "    worldview_dataset = []\n",
    "    \n",
    "    for item in dataset:\n",
    "        image = item[0]\n",
    "        label = item[1]\n",
    "        chessboard_black = torch.reshape(image, (8, 8, 12))\n",
    "        chessboard_black = chessboard_black.flip(0)\n",
    "        chessboard_black = chessboard_black.flip(2)\n",
    "        chessboard_black = torch.reshape(chessboard_black, (768,))\n",
    "        \n",
    "        temp = torch.cat((image, chessboard_black))\n",
    "        \n",
    "        worldview_dataset.append((temp, label))\n",
    "    \n",
    "    return worldview_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a4bb48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = worldview(traindata)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size = 100000\n",
    ")\n",
    "\n",
    "dataset = worldview(testdata)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size = 100000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06ccfa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple neural network\n",
    "n_in = 1536\n",
    "n_out = 3\n",
    "learning_rate = 0.001\n",
    "K = 1550\n",
    "P = 1.0\n",
    "epochs = 80\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_in, K) \n",
    "        torch.nn.init.kaiming_uniform_(self.fc1.weight) #He initialization\n",
    "        self.fc2 = nn.Linear(K, n_out)\n",
    "        torch.nn.init.kaiming_uniform_(self.fc2.weight) #He initialization\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "#criterion = torch.nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357139e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "traccs = []\n",
    "tsaccs = []\n",
    "for epoch in range(epochs):\n",
    "    correct = 0\n",
    "    size = 0\n",
    "    net.train()\n",
    "    for b, (x, y) in enumerate(trainloader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "        output = net(x)\n",
    "        #print(output)\n",
    "        #acu += (output.argmax(1) == y).float().sum().item()\n",
    "        cor = (output.argmax(1) == y).float().sum().item()\n",
    "\n",
    "        correct += cor\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        size += len(x)\n",
    "\n",
    "    #accs.append(100 * (acu / len(y_tr)))\n",
    "    traccs.append((100 * correct) / size)\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    size = 0\n",
    "    with torch.no_grad():\n",
    "        for b, (x, y) in enumerate(testloader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad() \n",
    "            output = net(x)\n",
    "            #print(output)\n",
    "            #acu += (output.argmax(1) == y).float().sum().item()\n",
    "            cor = (output.argmax(1) == y).float().sum().item()\n",
    "\n",
    "            correct += cor\n",
    "            size += len(x)\n",
    "\n",
    "        #accs.append(100 * (acu / len(y_tr)))\n",
    "        tsaccs.append((100 * correct) / size)\n",
    "\n",
    "print(\"max training accuracy: \", max(traccs))\n",
    "print(\"max testing accuracy: \", max(tsaccs))\n",
    "lab = \"training accuracy\"\n",
    "plt.figure(1)\n",
    "plt.plot(traccs, label=lab)\n",
    "plt.title(\"Change in Training Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "lab = \"testing accuracy\"\n",
    "plt.figure(2)\n",
    "plt.plot(tsaccs, label=lab)\n",
    "plt.title(\"Change in Testing Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26e00fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context(dataset):\n",
    "    \"\"\"\n",
    "    args:\n",
    "    dataset: Dataset of tensors\n",
    "   \n",
    "    returns: \n",
    "    context_dataset: Dataset\n",
    "    \"\"\"\n",
    "    context_dataset = []\n",
    "        \n",
    "    second_move = False\n",
    "    # the starting board is the first element of the dataset\n",
    "    starting_board = dataset[0][0]\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        temp = []\n",
    "        image, label = dataset[i]\n",
    "        if torch.equal(image, starting_board):\n",
    "            for j in range(3):\n",
    "                temp.append(starting_board.clone())\n",
    "                second_move = True\n",
    "        elif second_move:\n",
    "            for j in range(2):\n",
    "                temp.append(starting_board.clone())\n",
    "            temp.append(image)\n",
    "            second_move = False\n",
    "        else:\n",
    "            for j in range(3):\n",
    "                temp.append(dataset[i+j-2][0].clone())\n",
    "                \n",
    "        temp = torch.cat(temp)\n",
    "        context_dataset.append(temp)\n",
    "            \n",
    "    context_dataset = torch.stack(context_dataset)\n",
    "    new_dataset = torch.utils.data.TensorDataset(context_dataset, dataset[:][1])        \n",
    "    \n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b520ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = context(traindata)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size = 100000\n",
    ")\n",
    "\n",
    "dataset = context(testdata)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size = 100000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd413280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple neural network\n",
    "n_in = 2304\n",
    "n_out = 3\n",
    "learning_rate = 0.001\n",
    "K = 2310\n",
    "P = 1.0\n",
    "epochs = 80\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_in, K) \n",
    "        torch.nn.init.kaiming_uniform_(self.fc1.weight) #He initialization\n",
    "        self.fc2 = nn.Linear(K, n_out)\n",
    "        torch.nn.init.kaiming_uniform_(self.fc2.weight) #He initialization\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "#criterion = torch.nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a6c327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline\n",
    "traccs = []\n",
    "tsaccs = []\n",
    "for epoch in range(epochs):\n",
    "    correct = 0\n",
    "    size = 0\n",
    "    net.train()\n",
    "    for b, (x, y) in enumerate(trainloader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "        output = net(x)\n",
    "        #print(output)\n",
    "        #acu += (output.argmax(1) == y).float().sum().item()\n",
    "        cor = (output.argmax(1) == y).float().sum().item()\n",
    "\n",
    "        correct += cor\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        size += len(x)\n",
    "\n",
    "    #accs.append(100 * (acu / len(y_tr)))\n",
    "    traccs.append((100 * correct) / size)\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    size = 0\n",
    "    with torch.no_grad():\n",
    "        for b, (x, y) in enumerate(testloader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad() \n",
    "            output = net(x)\n",
    "            #print(output)\n",
    "            #acu += (output.argmax(1) == y).float().sum().item()\n",
    "            cor = (output.argmax(1) == y).float().sum().item()\n",
    "\n",
    "            correct += cor\n",
    "            size += len(x)\n",
    "\n",
    "        #accs.append(100 * (acu / len(y_tr)))\n",
    "        tsaccs.append((100 * correct) / size)\n",
    "\n",
    "print(\"max training accuracy: \", max(traccs))\n",
    "print(\"max testing accuracy: \", max(tsaccs))\n",
    "lab = \"training accuracy\"\n",
    "plt.figure(1)\n",
    "plt.plot(traccs, label=lab)\n",
    "plt.title(\"Change in Training Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "lab = \"testing accuracy\"\n",
    "plt.figure(2)\n",
    "plt.plot(tsaccs, label=lab)\n",
    "plt.title(\"Change in Testing Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad2eb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
